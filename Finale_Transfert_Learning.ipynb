{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfert_Learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgssE21NPJyS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de68f4f0-bb56-41fe-f8a8-8f7b5ad3e429"
      },
      "source": [
        "!pip show tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.4.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: typing-extensions, protobuf, wheel, astunparse, six, h5py, termcolor, grpcio, tensorflow-estimator, keras-preprocessing, wrapt, flatbuffers, numpy, opt-einsum, gast, google-pasta, absl-py, tensorboard\n",
            "Required-by: fancyimpute\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6li9rXjwsVEV"
      },
      "source": [
        "Cellule ci-dessous : split de data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 842
        },
        "id": "1HudZ9iaPmIU",
        "outputId": "38fe906c-ad04-49b4-e1c7-20a70c7f9137"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import os\r\n",
        "from glob import glob\r\n",
        "from PIL import Image, ImageFile\r\n",
        "import scipy.misc\r\n",
        "\r\n",
        "from keras.utils.np_utils import to_categorical # used for converting labels to one-hot-encoding\r\n",
        "\r\n",
        "def add_value_labels(ax, spacing=1):\r\n",
        "    \"\"\"Add labels to the end of each bar in a bar chart.\r\n",
        "    Arguments:\r\n",
        "        ax (matplotlib.axes.Axes): The matplotlib object containing the axes\r\n",
        "            of the plot to annotate.\r\n",
        "        spacing (int): The distance between the labels and the bars.\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    # For each bar: Place a label\r\n",
        "    for rect in ax.patches:\r\n",
        "        # Get X and Y placement of label from rect.\r\n",
        "        y_value = rect.get_height()\r\n",
        "        x_value = rect.get_x() + rect.get_width() / 2\r\n",
        "\r\n",
        "        # Number of points between bar and label. Change to your liking.\r\n",
        "        space = spacing\r\n",
        "        # Vertical alignment for positive values\r\n",
        "        va = 'bottom'\r\n",
        "\r\n",
        "        # If value of bar is negative: Place label below bar\r\n",
        "        if y_value < 0:\r\n",
        "            # Invert space to place label below\r\n",
        "            space *= -1\r\n",
        "            # Vertically align label at top\r\n",
        "            va = 'top'\r\n",
        "\r\n",
        "        # Use Y value as label and format number with one decimal place\r\n",
        "        label = y_value\r\n",
        "\r\n",
        "        # Create annotation\r\n",
        "        ax.annotate(\r\n",
        "            label,                      # Use `label` as label\r\n",
        "            (x_value, y_value),         # Place label at end of the bar\r\n",
        "            xytext=(0, space),          # Vertically shift label by `space`\r\n",
        "            textcoords=\"offset points\", # Interpret `xytext` as offset in points\r\n",
        "            ha='center',                # Horizontally center label\r\n",
        "            va=va)                      # Vertically align label differently for\r\n",
        "                                        # positive and negative values.\r\n",
        "\r\n",
        "\r\n",
        "# get dictionary with all file name in .jpg\r\n",
        "base_dir = '/content/drive/MyDrive/dataset-skin/HAM10000_images'\r\n",
        "\r\n",
        "imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x\r\n",
        "                     for x in glob(os.path.join(base_dir, '*', '*.jpg'))}\r\n",
        "print(len(imageid_path_dict))\r\n",
        "\r\n",
        "lesion_type_dict = {\r\n",
        "    'nv': 'Melanocytic nevi',\r\n",
        "    'mel': 'Melanoma',\r\n",
        "    'bkl': 'Benign keratosis-like lesions',\r\n",
        "    'bcc': 'Basal cell carcinoma',\r\n",
        "    'akiec': 'Actinic keratoses',\r\n",
        "    'vasc': 'Vascular lesions',\r\n",
        "    'df': 'Dermatofibroma'\r\n",
        "}\r\n",
        "\r\n",
        "# Read in the csv of metadata\r\n",
        "tile_df = pd.read_csv(os.path.join(base_dir, '/content/drive/MyDrive/dataset-skin/HAM10000_metadata.csv'))\r\n",
        "\r\n",
        "# Create some new columns (path to image, human-readable name) and review them\r\n",
        "tile_df['path'] = tile_df['image_id'].map(imageid_path_dict.get)\r\n",
        "tile_df['cell_type'] = tile_df['dx'].map(lesion_type_dict.get) \r\n",
        "tile_df['cell_type_idx'] = pd.Categorical(tile_df['cell_type']).codes\r\n",
        "\r\n",
        "# distribution of different cell types\r\n",
        "fig, ax1 = plt.subplots(1, 1, figsize= (10, 7))\r\n",
        "tile_df['dx'].value_counts().plot(kind='bar', ax=ax1)\r\n",
        "plt.title('Image Distribution')\r\n",
        "plt.xlabel('Classes')\r\n",
        "plt.ylabel('Number of Images')\r\n",
        "add_value_labels(ax1)\r\n",
        "\r\n",
        "fig.savefig('Distribution.png')\r\n",
        "\r\n",
        "\r\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\r\n",
        "Image.open('/content/drive/MyDrive/dataset-skin/HAM10000_images/ISIC_0028905.jpg').resize((224,224))\r\n",
        "#tile_df['image'] = ('/content/drive/MyDrive/dataset-skin/HAM10000_images/'+tile_df['image_id']+'.jpg').map(lambda x: np.asarray(Image.open(x).resize((224,224))))\r\n",
        "\r\n",
        "n_samples = 5\r\n",
        "fig, m_axs = plt.subplots(7, n_samples, figsize = (4*n_samples, 3*7))\r\n",
        "for n_axs, (type_name, type_rows) in zip(m_axs, \r\n",
        "                                         tile_df.sort_values(['cell_type']).groupby('cell_type')):\r\n",
        "    n_axs[0].set_title(type_name)\r\n",
        "    for c_ax, (_, c_row) in zip(n_axs, type_rows.sample(n_samples, random_state=2018).iterrows()):\r\n",
        "        c_ax.imshow(c_row['image'])\r\n",
        "        c_ax.axis('off')\r\n",
        "fig.savefig('category_samples.png', dpi=300)\r\n",
        "\r\n",
        "y = tile_df.cell_type_idx\r\n",
        "\r\n",
        "#make training, validation, and test split of the data\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "x_train_o, x_test_o, y_train_o, y_test_o = train_test_split(tile_df, y, test_size=0.2)\r\n",
        "\r\n",
        "\r\n",
        "# Perform one-hot encoding on the labels\r\n",
        "y_train = to_categorical(y_train_o, num_classes = 7)\r\n",
        "y_test = to_categorical(y_test_o, num_classes = 7)\r\n",
        "\r\n",
        "x_train, x_validate, y_train, y_validate = train_test_split(x_train_o, y_train, test_size = 0.25)\r\n",
        "'''\r\n",
        "x_train = x_train.reshape(x_train.shape[0], *(224, 224, 3))\r\n",
        "x_test = x_test.reshape(x_test.shape[0], *(224, 224, 3))\r\n",
        "x_validate = x_validate.reshape(x_validate.shape[0], *(224, 224, 3))\r\n",
        "'''\r\n",
        "\r\n",
        "#create split folders for the data set\r\n",
        "data_path = '/content/drive/MyDrive/dataset-skin/data_split2'\r\n",
        "# create a path to 'base_dir' to which we will join the names of the new folders\r\n",
        "# train_dir\r\n",
        "train_dir = os.path.join(data_path, 'train_dir')\r\n",
        "os.mkdir(train_dir)\r\n",
        "\r\n",
        "# val_dir\r\n",
        "val_dir = os.path.join(data_path, 'val_dir')\r\n",
        "os.mkdir(val_dir)\r\n",
        "\r\n",
        "#test_dir\r\n",
        "test_dir = os.path.join(data_path, 'test_dir')\r\n",
        "os.mkdir(test_dir)\r\n",
        "\r\n",
        "def make_cat_folders(path):\r\n",
        "    nv = os.path.join(path, 'nv')\r\n",
        "    os.mkdir(nv)\r\n",
        "    mel = os.path.join(path, 'mel')\r\n",
        "    os.mkdir(mel)\r\n",
        "    bkl = os.path.join(path, 'bkl')\r\n",
        "    os.mkdir(bkl)\r\n",
        "    bcc = os.path.join(path, 'bcc')\r\n",
        "    os.mkdir(bcc)\r\n",
        "    akiec = os.path.join(path, 'akiec')\r\n",
        "    os.mkdir(akiec)\r\n",
        "    vasc = os.path.join(path, 'vasc')\r\n",
        "    os.mkdir(vasc)\r\n",
        "    df = os.path.join(path, 'df')\r\n",
        "    os.mkdir(df)\r\n",
        "    \r\n",
        "make_cat_folders(train_dir)\r\n",
        "make_cat_folders(val_dir)\r\n",
        "make_cat_folders(test_dir)\r\n",
        "\r\n",
        "def save_split(path, data):\r\n",
        "    images = data['image'].tolist()\r\n",
        "    image_id = data['image_id'].tolist()\r\n",
        "    image_dx = data['dx'].tolist()\r\n",
        "    \r\n",
        "    for i in range(len(images)):\r\n",
        "        images[i] = images[i]*(1/255)\r\n",
        "    \r\n",
        "    for i in range(len(images)):\r\n",
        "        scipy.misc.imsave((path+'/'+image_dx[i]+'/'+image_id[i]+'.jpg'), images[i])\r\n",
        "\r\n",
        "save_split(train_dir, x_train)\r\n",
        "save_split(test_dir, x_test_o)\r\n",
        "save_split(val_dir, x_validate)\r\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "UnidentifiedImageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-776e1fece64e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;31m#tile_df['image'] = tile_df['path'].map(lambda x: np.asarray(Image.open(x).resize((100,75))))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0mImageFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLOAD_TRUNCATED_IMAGES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/dataset-skin/HAM10000_images/ISIC_0028905.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;31m#tile_df['image'] = ('/content/drive/MyDrive/dataset-skin/HAM10000_images/'+tile_df['image_id']+'.jpg').map(lambda x: np.asarray(Image.open(x).resize((224,224))))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2860\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2861\u001b[0m     raise UnidentifiedImageError(\n\u001b[0;32m-> 2862\u001b[0;31m         \u001b[0;34m\"cannot identify image file %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2863\u001b[0m     )\n\u001b[1;32m   2864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file '/content/drive/MyDrive/dataset-skin/HAM10000_images/ISIC_0028905.jpg'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09WWfZZ4scK9"
      },
      "source": [
        "Cellule ci-dessous : Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHbFuS9XK49v"
      },
      "source": [
        "from numpy.random import seed\r\n",
        "seed(101)\r\n",
        "from tensorflow import set_random_seed\r\n",
        "set_random_seed(101)\r\n",
        "import numpy as np\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "\r\n",
        "import os\r\n",
        "import shutil\r\n",
        "\r\n",
        "path='/content/drive/MyDrive/dataset-skin/HAM10000_images'\r\n",
        "path2 = '/content/drive/MyDrive/dataset-skin/HAM10000_images/data_split2'\r\n",
        "\r\n",
        "# note that we are not augmenting class 'nv'\r\n",
        "class_list = ['mel','bkl','bcc','akiec','vasc','df']\r\n",
        "\r\n",
        "for item in class_list:\r\n",
        "    \r\n",
        "    # We are creating temporary directories here because we delete these directories later\r\n",
        "    # create a base dir\r\n",
        "    aug_dir = 'E://aug_dir'\r\n",
        "    os.mkdir(aug_dir)\r\n",
        "    # create a dir within the base dir to store images of the same class\r\n",
        "    img_dir = os.path.join(aug_dir, 'img_dir')\r\n",
        "    os.mkdir(img_dir)\r\n",
        "\r\n",
        "    # Choose a class\r\n",
        "    img_class = item\r\n",
        "\r\n",
        "    # list all images in that directory\r\n",
        "    img_list = os.listdir(path2+'/train_dir/' + img_class)\r\n",
        "\r\n",
        "    # Copy images from the class train dir to the img_dir e.g. class 'mel'\r\n",
        "    for fname in img_list:\r\n",
        "            # source path to image\r\n",
        "            src = os.path.join(path2+'/train_dir/' + img_class, fname)\r\n",
        "            # destination path to image\r\n",
        "            dst = os.path.join(img_dir, fname)\r\n",
        "            # copy the image from the source to the destination\r\n",
        "            shutil.copyfile(src, dst)\r\n",
        "\r\n",
        "\r\n",
        "    # point to a dir containing the images and not to the images themselves\r\n",
        "    path = aug_dir\r\n",
        "    save_path = path2+'/train_dir/' + img_class\r\n",
        "\r\n",
        "    # Create a data generator\r\n",
        "    datagen = ImageDataGenerator(\r\n",
        "        rotation_range=180,\r\n",
        "        width_shift_range=0.1,\r\n",
        "        height_shift_range=0.1,\r\n",
        "        zoom_range=0.1,\r\n",
        "        horizontal_flip=True,\r\n",
        "        vertical_flip=True,\r\n",
        "        #brightness_range=(0.9,1.1),\r\n",
        "        fill_mode='nearest')\r\n",
        "\r\n",
        "    batch_size = 50\r\n",
        "\r\n",
        "    aug_datagen = datagen.flow_from_directory(path,\r\n",
        "                                           save_to_dir=save_path,\r\n",
        "                                           save_format='jpg',\r\n",
        "                                                    target_size=(224,224),\r\n",
        "                                                    batch_size=batch_size)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    # Generate the augmented images and add them to the training folders\r\n",
        "    \r\n",
        "    ###########\r\n",
        "    \r\n",
        "    num_aug_images_wanted = 700 # total number of images we want to have in each class\r\n",
        "    \r\n",
        "    ###########\r\n",
        "    \r\n",
        "    num_files = len(os.listdir(img_dir))\r\n",
        "    num_batches = int(np.ceil((num_aug_images_wanted-num_files)/batch_size))\r\n",
        "\r\n",
        "    # run the generator and create about 6000 augmented images\r\n",
        "    for i in range(0,num_batches):\r\n",
        "\r\n",
        "        imgs, labels = next(aug_datagen)\r\n",
        "        \r\n",
        "    # delete temporary directory with the raw image files\r\n",
        "    shutil.rmtree('E://aug_dir')\r\n",
        "    \r\n",
        "print(len(os.listdir(path2+'/train_dir/nv')))\r\n",
        "print(len(os.listdir(path2+'/train_dir/mel')))\r\n",
        "print(len(os.listdir(path2+'/train_dir/bkl')))\r\n",
        "print(len(os.listdir(path2+'/train_dir/bcc')))\r\n",
        "print(len(os.listdir(path2+'/train_dir/akiec')))\r\n",
        "print(len(os.listdir(path2+'/train_dir/vasc')))\r\n",
        "print(len(os.listdir(path2+'/train_dir/df')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3jzacc8LeAf"
      },
      "source": [
        "import cv2\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "from glob import glob\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "\r\n",
        "def normalize_color_image(img_path):\r\n",
        "    image = cv2.imread(img_path)\r\n",
        "    channels = cv2.split(image)\r\n",
        "    eq_channels = []\r\n",
        "    for ch, color in zip(channels, ['B', 'G', 'R']):\r\n",
        "        eq_channels.append(cv2.equalizeHist(ch))\r\n",
        "\r\n",
        "    eq_image = cv2.merge(eq_channels)\r\n",
        "    eq_image = cv2.cvtColor(eq_image, cv2.COLOR_BGR2RGB)\r\n",
        "    return eq_image\r\n",
        "    \r\n",
        "    \r\n",
        "\r\n",
        "\r\n",
        "train_path = '/content/drive/MyDrive/dataset-skin/HAM10000_images/data_split3/train_dir' \r\n",
        "valid_path = '/content/drive/MyDrive/dataset-skin/HAM10000_images/data_split3/val_dir' \r\n",
        "test_path = '/content/drive/MyDrive/dataset-skin/HAM10000_images/data_split3/test_dir'\r\n",
        "\r\n",
        "train_pics = glob(train_path+\"/*/*.jpg\")\r\n",
        "val_pics = glob(valid_path+\"/*/*.jpg\")\r\n",
        "test_pics = glob(test_path+\"/*/*.jpg\")\r\n",
        "\r\n",
        "for pic in train_pics:\r\n",
        "    img = normalize_color_image(pic)\r\n",
        "    cv2.imwrite(pic, img)\r\n",
        "for pic in val_pics:\r\n",
        "    img = normalize_color_image(pic)\r\n",
        "    cv2.imwrite(pic, img)\r\n",
        "for pic in test_pics:\r\n",
        "    img = normalize_color_image(pic)\r\n",
        "    cv2.imwrite(pic, img)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uxi_1ZdslDk"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgLSCaKpLlLX"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import itertools\r\n",
        "\r\n",
        "from keras import models\r\n",
        "from keras.preprocessing import image\r\n",
        "\r\n",
        "\r\n",
        "def save_training_graph(history, filename):\r\n",
        "    fig, ax = plt.subplots(2,1)\r\n",
        "    ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\r\n",
        "    ax[0].plot(history.history['val_loss'], color='r', label=\"Validation loss\",axes =ax[0])\r\n",
        "    legend = ax[0].legend(loc='best', shadow=True)\r\n",
        "    \r\n",
        "    ax[1].plot(history.history['acc'], color='b', label=\"Training accuracy\")\r\n",
        "    ax[1].plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\r\n",
        "    legend = ax[1].legend(loc='best', shadow=True)\r\n",
        "    fig.savefig(filename)\r\n",
        "    \r\n",
        "def plot_confusion_matrix(cm, classes,\r\n",
        "                          normalize=False,\r\n",
        "                          title='Confusion matrix',\r\n",
        "                          cmap=plt.cm.Blues):\r\n",
        "    \"\"\"\r\n",
        "    This function prints and plots the confusion matrix.\r\n",
        "    Normalization can be applied by setting `normalize=True`.\r\n",
        "    \"\"\"\r\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\r\n",
        "    plt.title(title)\r\n",
        "    plt.colorbar()\r\n",
        "    tick_marks = np.arange(len(classes))\r\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\r\n",
        "    plt.yticks(tick_marks, classes)\r\n",
        "\r\n",
        "    if normalize:\r\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\r\n",
        "\r\n",
        "    thresh = cm.max() / 2.\r\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\r\n",
        "        plt.text(j, i, cm[i, j],\r\n",
        "                 horizontalalignment=\"center\",\r\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\r\n",
        "\r\n",
        "    plt.tight_layout()\r\n",
        "    plt.ylabel('True label')\r\n",
        "    plt.xlabel('Predicted label')\r\n",
        "    plt.savefig('Confusion_Matrix.png')\r\n",
        "    \r\n",
        "def vis_activation(model, img_path):\r\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\r\n",
        "    img_tensor = image.img_to_array(img)\r\n",
        "    img_tensor = np.expand_dims(img_tensor, axis=0)\r\n",
        "    img_tensor /= 255.\r\n",
        "    \r\n",
        "    plt.imshow(img_tensor[0])\r\n",
        "    plt.show()\r\n",
        "    print(img_tensor.shape)\r\n",
        "    \r\n",
        "    layer_outputs = [layer.output for layer in model.layers[1:19]] \r\n",
        "    activation_model = models.Model(inputs=model.input, outputs=layer_outputs) \r\n",
        "    # Creates a model that will return these outputs, given the model input\r\n",
        "    \r\n",
        "    activations = activation_model.predict(img_tensor)\r\n",
        "    \r\n",
        "    layer_names = []\r\n",
        "    for layer in model.layers[1:19]:\r\n",
        "    \tlayer_names.append(layer.name) # Names of the layers, so you can have them as part of your plot\r\n",
        "    \t\r\n",
        "    images_per_row = 16\r\n",
        "    \r\n",
        "    for layer_name, layer_activation in zip(layer_names, activations): # Displays the feature maps\r\n",
        "    \tn_features = layer_activation.shape[-1] # Number of features in the feature map\r\n",
        "    \twidth = layer_activation.shape[1] #The feature map has shape (1, size, size, n_features).\r\n",
        "    \theight = layer_activation.shape[2]\r\n",
        "    \tn_cols = n_features // images_per_row # Tiles the activation channels in this matrix\r\n",
        "    \tdisplay_grid = np.zeros((width * n_cols, images_per_row * height))\r\n",
        "    \t\r\n",
        "    \tfor col in range(n_cols): # Tiles each filter into a big horizontal grid \r\n",
        "    \t\tfor row in range(images_per_row):\r\n",
        "    \t\t\tchannel_image = layer_activation[0,:, :,col * images_per_row + row]\r\n",
        "    \t\t\tchannel_image -= channel_image.mean() # Post-processes the feature to make it visually palatable\r\n",
        "    \t\t\tchannel_image /= channel_image.std()\r\n",
        "    \t\t\tchannel_image *= 64\r\n",
        "    \t\t\tchannel_image += 128\r\n",
        "    \t\t\tchannel_image = np.clip(channel_image, 0, 255).astype('uint8')\r\n",
        "    \t\t\tdisplay_grid[col * width : (col + 1) * width, # Displays the grid\r\n",
        "    \t\t\t\t\t\t row * height : (row + 1) * height] = channel_image\r\n",
        "    \t#scale = 1. / (224)\r\n",
        "    \t#plt.figure(figsize=(scale * display_grid.shape[1],\r\n",
        "    \t#\t\t\t\t\tscale * display_grid.shape[0]))\r\n",
        "    \tplt.title(layer_name)\r\n",
        "    \tplt.grid(False)\r\n",
        "    \tplt.imshow(display_grid, aspect='auto', cmap='viridis')\r\n",
        "    \tplt.savefig('layer_'+layer_name+'.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3mA0IaVsn_E"
      },
      "source": [
        "Cellule ci-dessous : Training \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxINvMS3Lu5H"
      },
      "source": [
        "import numpy as np\r\n",
        "import keras\r\n",
        "from keras.layers import Dense, Dropout, Flatten\r\n",
        "from keras.applications import VGG16\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "from keras.models import Model, load_model\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\r\n",
        "import keras.optimizers \r\n",
        "from model_utils import save_training_graph, plot_confusion_matrix, vis_activation\r\n",
        "from sklearn.metrics import classification_report, confusion_matrix\r\n",
        "from keras.applications.vgg16 import preprocess_input\r\n",
        "\r\n",
        "base_model=VGG16(weights='imagenet',include_top=False, input_shape=(224,224,3))\r\n",
        "\r\n",
        "top_model = Sequential()\r\n",
        "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\r\n",
        "top_model.add(Dense(1024,activation='relu'))\r\n",
        "top_model.add(Dropout(.50))\r\n",
        "top_model.add(Dense(512,activation='relu'))\r\n",
        "top_model.add(Dropout(.25))\r\n",
        "\r\n",
        "top_model.add(Dense(7,activation='softmax')) #final layer with softmax activation\r\n",
        "\r\n",
        "model=Model(inputs=base_model.input,outputs=top_model(base_model.output))\r\n",
        "print(model.summary())\r\n",
        "\r\n",
        "#Each one of those commands represents one experiment with trainable layers\r\n",
        "'''\r\n",
        "for layer in model.layers[:20]:\r\n",
        "    layer.trainable = False\r\n",
        "   \r\n",
        "for layer in model.layers[1:7]:\r\n",
        "    layer.trainable = False\r\n",
        "for layer in model.layers[15:]:\r\n",
        "    layer.trainable = False\r\n",
        "for layer in model.layers:\r\n",
        "    print(layer, layer.trainable)\r\n",
        "'''\r\n",
        "\r\n",
        "train_datagen=ImageDataGenerator(\r\n",
        "    preprocessing_function=preprocess_input,\r\n",
        "    shear_range=0.2,\r\n",
        "    zoom_range=0.2,\r\n",
        "    rotation_range=20,\r\n",
        "    horizontal_flip=True,\r\n",
        "    fill_mode='nearest')\r\n",
        "\r\n",
        "valid_datagen=ImageDataGenerator(\r\n",
        "        preprocessing_function=preprocess_input)\r\n",
        "\r\n",
        "train_path = '/content/drive/MyDrive/dataset-skin/HAM10000_images/data_split/train_dir' \r\n",
        "valid_path = '/content/drive/MyDrive/dataset-skin/HAM10000_images/data_split/val_dir' \r\n",
        "test_path = '/content/drive/MyDrive/dataset-skin/HAM10000_images/data_split/test_dir' \r\n",
        "\r\n",
        "train_generator = train_datagen.flow_from_directory(train_path,\r\n",
        "                                                 target_size=(224,224),\r\n",
        "                                                 color_mode='rgb',\r\n",
        "                                                 batch_size=10,\r\n",
        "                                                 class_mode='categorical',\r\n",
        "                                                 shuffle=True)\r\n",
        "\r\n",
        "valid_gen = valid_datagen.flow_from_directory(valid_path,\r\n",
        "                                            target_size=(224,224),\r\n",
        "                                            color_mode = \"rgb\",\r\n",
        "                                            class_mode=\"categorical\",\r\n",
        "                                            batch_size=10)\r\n",
        "\r\n",
        "test_gen = valid_datagen.flow_from_directory(test_path,\r\n",
        "                                            target_size=(224,224),\r\n",
        "                                            color_mode = \"rgb\",\r\n",
        "                                            class_mode=\"categorical\",\r\n",
        "                                            batch_size=1,\r\n",
        "                                            shuffle=False)\r\n",
        "\r\n",
        "# loss function will be categorical cross entropy\r\n",
        "# evaluation metric will be accuracy\r\n",
        "sgd = keras.optimizers.SGD(lr=1e-4, decay=1e-6, momentum=0.9, nesterov=True)\r\n",
        "adam = keras.optimizers.Adam(lr=.00001)\r\n",
        "model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\r\n",
        "\r\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \r\n",
        "                                            patience=3, \r\n",
        "                                            verbose=1, \r\n",
        "                                            factor=0.5, \r\n",
        "                                            min_lr=0.00001)\r\n",
        "\r\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss',\r\n",
        "                              min_delta=0,\r\n",
        "                              patience=5,\r\n",
        "                              verbose=0, mode='auto')\r\n",
        "\r\n",
        "checkpointer = ModelCheckpoint(filepath=\"best_weights_model.hdf5\", \r\n",
        "                               monitor = 'val_acc',\r\n",
        "                               verbose=1, \r\n",
        "                               save_best_only=True)\r\n",
        "\r\n",
        "step_size_train=train_generator.n//train_generator.batch_size\r\n",
        "step_size_val=valid_gen.n//valid_gen.batch_size\r\n",
        "\r\n",
        "history = model.fit_generator(generator=train_generator,\r\n",
        "                   steps_per_epoch=step_size_train,\r\n",
        "                   callbacks=[checkpointer,learning_rate_reduction,early_stop],\r\n",
        "                   validation_data=valid_gen,\r\n",
        "                   validation_steps=step_size_val,\r\n",
        "                   epochs=50)\r\n",
        "\r\n",
        "model = load_model('best_weights_model.hdf5')\r\n",
        "scores = model.evaluate_generator(generator=test_gen,steps=test_gen.n//test_gen.batch_size)\r\n",
        "print(str(scores[0]), str(scores[1]))\r\n",
        "\r\n",
        "Y_pred = model.predict_generator(test_gen,test_gen.n//test_gen.batch_size)\r\n",
        "y_pred = np.argmax(Y_pred, axis=1)\r\n",
        "print('Confusion Matrix')\r\n",
        "confusion_mtx=confusion_matrix(test_gen.classes, y_pred)\r\n",
        "print(confusion_mtx)\r\n",
        "plot_confusion_matrix(confusion_mtx, classes = range(7))\r\n",
        "\r\n",
        "print('Classification Report')\r\n",
        "target_names = ['akiec','bcc','bkl','df','mel','nv','vasc']\r\n",
        "print(classification_report(test_gen.classes, y_pred,target_names=target_names))\r\n",
        "\r\n",
        "save_training_graph(history, 'Pretrained Training Accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}